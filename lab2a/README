# NAME: John Tran
# EMAIL: johntran627@gmail.com
# UID: 005183495
# SLIPDAYS: 3

README: description of each included files and other related information

lab2_add.c: a program that uses locks on simple operation

lab2_list.c: a program that uses locks on complex data structure

SortedList.h: the given head file

SortedList.c: the implementations of functions in the header file

Makefile: build the required deliverable programs

test_add.sh & test_list.sh: test scripts

lab2_add.gp & lab2_list.gp: the provided files to make graphs

lab2_add-1.png ... threads and iterations required to generate a failure (with and without yields)
lab2_add-2.png ... average time per operation with and without yields.
lab2_add-3.png ... average time per (single threaded) operation vs. the number of iterations.
lab2_add-4.png ... threads and iterations that can run successfully with yields under each of the synchronization options.
lab2_add-5.png ... average time per (protected) operation vs. the number of threads.
For part 2 (lab2_list):
lab2_list-1.png ... average time per (single threaded) unprotected operation vs. number of iterations (illustrating the correction of the per-operation cost for the list length).
lab2_list-2.png ... threads and iterations required to generate a failure (with and without yields).
lab2_list-3.png ... iterations that can run (protected) without failure.
lab2_list-4.png ... (length-adjusted) cost per operation vs the number of threads for the various synchronization options.


QUESTION 2.1.1 - causing conflicts:
Why does it take many iterations before errors are seen?
Why does a significantly smaller number of iterations so seldom fail?
Because the critical section is small, so the probability of multiple threads entering 
the critical section is small. Thus it takes many iterations before errors are seen.
Thread creation takes time so that it may take awhile for a thread to catch up with the 
previously created thread, and thus significant smaller number of iterations so seldom fail. 


QUESTION 2.1.2 - cost of yielding:
Why are the --yield runs so much slower?
Where is the additional time going?
Is it possible to get valid per-operation timings if we are using the --yield option?
If so, explain how. If not, explain why not.
Yield runs so much slower because every time a process yields, it gives up the CPU so that 
other processes can run, and thus a context switch will happen. Since the cost of context 
switch is very high, if a process yields frequently, it would run much more slower.
Since the total runtime we record already contains the time of context switches, it’s not 
possible to get a valid per-operation timings if we are using the –yield option.

QUESTION 2.1.3 - measurement errors:
Why does the average cost per operation drop with increasing iterations?
If the cost per iteration is a function of the number of iterations, how do we know how 
many iterations to run (or what the "correct" cost is)?
Thread creation is more expensive than iterations in a loop. Thus, given a fixed number of 
threads, if the number of iterations increases, the cost of thread creation will become 
cheaper and cheaper, so the average cost per operation will drop.
If the cost per iteration is a function of the number of iterations, we can figure out the 
true cost by keep increasing the number of iterations. Eventually, it would reach an 
approximately equilibrium point. It means that even though we can keep increasing the 
number of iterations to be bigger than the equilibrium point, the difference is not much.

QUESTION 2.1.4 - costs of serialization:
Why do all of the options perform similarly for low numbers of threads?
Why do the three protected operations slow down as the number of threads rises?
When the number of threads is small, the probability of getting race conditions is also 
small. Thus, all of the options perform similarly. 
However, when the number of threads increases, race conditions are likely to happen and 
each thread is likely to have to wait for other threads to finish to obtain the lock; thus 
slow down operations.

QUESTION 2.2.1 - scalability of Mutex
Compare the variation in time per mutex-protected operation vs the number of threads in 
Part-1 (adds) and Part-2 (sorted lists).
Comment on the general shapes of the curves, and explain why they have this shape.
Comment on the relative rates of increase and differences in the shapes of the curves, and 
offer an explanation for these differences.
The performances of part 1 and part 2 look relatively the same (linear shape). The reason 
is that as the number as threads increases, these threads have to wait longer to obtain the lock. Also, the cost per operation of sorted lists seems to grow faster than the cost per operation of adds because list traversal is much more expensive than adding operation. 


QUESTION 2.2.2 - scalability of spin locks
Compare the variation in time per protected operation vs the number of threads for list operations protected by Mutex vs Spin locks. Comment on the general shapes of the curves, and explain why they have this shape.
Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.
The curves of mutex and spin locks can be considered to be relatively linear. However, as the number of threads increases, threads in spin locks have to spin longer in order to obtain the lock.

